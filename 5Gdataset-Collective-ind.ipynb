{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "928dee3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1215890, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-1cad4d3a42e6>:46: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_full = df_full.fillna(df_full.median())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    " \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import random\n",
    "import math\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "import torch\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import copy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "sm = SMOTE(random_state=42)\n",
    "\n",
    "testset_frac = 0.25\n",
    "data_samples = 100000 \n",
    "\n",
    "df_full = pd.read_csv('data/Encoded.csv')\n",
    "print(df_full.shape)\n",
    "df_full = df_full.sample(n=data_samples)\n",
    "df_full = df_full.iloc[:, 1:]\n",
    "df_full = df_full.drop(columns=['Attack Tool', 'Label', 'sVid', 'dVid', '54'])\n",
    "df_full = df_full.fillna(df_full.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aaa4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "numEpoch = 20\n",
    "batch_size = 32\n",
    "momentum = 0.9\n",
    "print_amount=3\n",
    "number_of_slices = 5\n",
    "isSmote = False\n",
    "runtime = 22\n",
    "\n",
    "file_name = \"5G_federated_\" + str(isSmote) + \"_\" + str(number_of_slices)  + \"_\" + str(runtime) + \".txt\"\n",
    "file = open(file_name, \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8e1c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Benign', 'HTTPFlood', 'ICMPFlood', 'SYNFlood', 'SYNScan',\n",
      "       'SlowrateDoS', 'TCPConnectScan', 'UDPFlood', 'UDPScan'],\n",
      "      dtype='object')\n",
      "Benign            39272\n",
      "UDPFlood          37492\n",
      "HTTPFlood         11588\n",
      "SlowrateDoS        6076\n",
      "TCPConnectScan     1676\n",
      "SYNScan            1653\n",
      "UDPScan            1289\n",
      "SYNFlood            855\n",
      "ICMPFlood            99\n",
      "Name: Attack Type, dtype: int64\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "dummies = pd.get_dummies(df_full['Attack Type'])  # Classification\n",
    "outcomes = dummies.columns\n",
    "print(outcomes)\n",
    "num_classes = len(outcomes)\n",
    "Y = dummies.values\n",
    "print(df_full['Attack Type'].value_counts())\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5b1585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39272, 90)\n",
      "(11588, 90)\n",
      "(37492, 90)\n",
      "(1653, 90)\n",
      "(6076, 90)\n",
      "0    39272\n",
      "1    37492\n",
      "2    11588\n",
      "3     6076\n",
      "4     1653\n",
      "Name: Attack Type, dtype: int64\n",
      "(96081, 90)\n",
      "(96081,)\n"
     ]
    }
   ],
   "source": [
    "df_Benign = df_full[df_full['Attack Type']=='Benign']\n",
    "df_HTTPFlood= df_full[df_full['Attack Type']=='HTTPFlood']\n",
    "df_UDPFlood= df_full[df_full['Attack Type']=='UDPFlood']\n",
    "df_SYNFlood= df_full[df_full['Attack Type']=='SYNScan']\n",
    "df_SlowrateDoS= df_full[df_full['Attack Type']=='SlowrateDoS']\n",
    "\n",
    "df_Benign.loc[(df_Benign['Attack Type'] == 'Benign'), 'Attack Type'] = 0\n",
    "df_HTTPFlood.loc[(df_HTTPFlood['Attack Type'] == 'HTTPFlood'), 'Attack Type'] = 2\n",
    "df_UDPFlood.loc[(df_UDPFlood['Attack Type'] == 'UDPFlood'), 'Attack Type'] = 1\n",
    "df_SYNFlood.loc[(df_SYNFlood['Attack Type'] == 'SYNScan'), 'Attack Type'] = 4\n",
    "df_SlowrateDoS.loc[(df_SlowrateDoS['Attack Type'] == 'SlowrateDoS'), 'Attack Type'] = 3\n",
    "\n",
    "print(df_Benign.shape)\n",
    "print(df_HTTPFlood.shape)\n",
    "print(df_UDPFlood.shape)\n",
    "print(df_SYNFlood.shape)\n",
    "print(df_SlowrateDoS.shape)\n",
    "\n",
    "df_filterd = pd.concat([df_Benign,df_HTTPFlood,df_UDPFlood,df_SYNFlood,df_SlowrateDoS])\n",
    "print(df_filterd['Attack Type'].value_counts())\n",
    "print(df_filterd.shape)\n",
    "type_df = df_filterd['Attack Type'].copy()\n",
    "data_df = df_filterd.drop('Attack Type',axis=1)\n",
    "print(type_df.shape)\n",
    "\n",
    "\n",
    "data_df = data_df / data_df.max()\n",
    "df_normalized = pd.concat([data_df,type_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d026eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_train_test(df, propotion=0.1):\n",
    "    \n",
    "    df_train = {}\n",
    "    df_test = []\n",
    "    for key,val in df['Attack Type'].value_counts().iteritems():\n",
    "        df_part = df[df['Attack Type'] == key]\n",
    "        df_part = df_part.dropna(axis=1)\n",
    "        df_test.append(df_part[0: int(df_part.shape[0]*propotion)])\n",
    "        df_train[key] = df_part[int(df_part.shape[0]*propotion):df_part.shape[0]]\n",
    "        \n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2faec961",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_slices(df_train, number_of_slices, isSmote=False, x_name=\"x_train\", y_name=\"y_train\"):\n",
    "    \n",
    "    df_normal = df_train.get(0) # benign\n",
    "    df_dos = df_train.get(1) # dos = udpflood\n",
    "    df_u2r = df_train.get(2) # u2r = httpflood\n",
    "    df_r2u = df_train.get(3) # r2u = slowratedos\n",
    "    df_probe = df_train.get(4) # probe = synscan\n",
    "    \n",
    "    df_normal_s1 = df_normal[int(df_normal.shape[0]*0/number_of_slices):int(df_normal.shape[0]*(1)/number_of_slices)]\n",
    "    df_normal_s2 = df_normal[int(df_normal.shape[0]*1/number_of_slices):int(df_normal.shape[0]*(2)/number_of_slices)]\n",
    "    df_normal_s3 = df_normal[int(df_normal.shape[0]*2/number_of_slices):int(df_normal.shape[0]*(3)/number_of_slices)]\n",
    "    df_normal_s4 = df_normal[int(df_normal.shape[0]*3/number_of_slices):int(df_normal.shape[0]*(4)/number_of_slices)]\n",
    "    df_normal_s5 = df_normal[int(df_normal.shape[0]*4/number_of_slices):int(df_normal.shape[0]*(5)/number_of_slices)]\n",
    "\n",
    "    df_s1 = pd.concat([df_normal_s1,df_dos])\n",
    "    df_s2 = pd.concat([df_normal_s2,df_u2r])\n",
    "    df_s3 = pd.concat([df_normal_s3,df_r2u])\n",
    "    df_s4 = pd.concat([df_normal_s4,df_probe])\n",
    "    df_s5 = df_normal_s5\n",
    "\n",
    "    x_data_dict= dict()\n",
    "    y_data_dict= dict()\n",
    "\n",
    "    y_s1 = (df_s1.pop('Attack Type').values).astype('int')\n",
    "    unique, counts = np.unique(y_s1, return_counts=True)\n",
    "    print('slice 1: ')\n",
    "    print(dict(zip(unique, counts)))\n",
    "    y_info1 = torch.tensor(y_s1).type(torch.LongTensor)\n",
    "    x_info1 = torch.tensor(df_s1.values).float()\n",
    "\n",
    "    y_s2 = (df_s2.pop('Attack Type').values).astype('int')\n",
    "    unique, counts = np.unique(y_s2, return_counts=True)\n",
    "    print('slice 2: ')\n",
    "    print(dict(zip(unique, counts)))\n",
    "    y_info2 = torch.tensor(y_s2).type(torch.LongTensor)\n",
    "    x_info2 = torch.tensor(df_s2.values).float()\n",
    "\n",
    "    y_s3 = (df_s3.pop('Attack Type').values).astype('int')\n",
    "    unique, counts = np.unique(y_s3, return_counts=True)\n",
    "    print('slice 3: ')\n",
    "    print( dict(zip(unique, counts)))\n",
    "    y_info3 = torch.tensor(y_s3).type(torch.LongTensor)\n",
    "    x_info3 = torch.tensor(df_s3.values).float()\n",
    "\n",
    "    y_s4 = (df_s4.pop('Attack Type').values).astype('int')\n",
    "    unique, counts = np.unique(y_s4, return_counts=True)\n",
    "    print('slice 4: ')\n",
    "    print(dict(zip(unique, counts)))\n",
    "    y_info4 = torch.tensor(y_s4).type(torch.LongTensor)\n",
    "    x_info4 = torch.tensor(df_s4.values).float()\n",
    "\n",
    "    y_s5 = (df_s5.pop('Attack Type').values).astype('int')\n",
    "    unique, counts = np.unique(y_s5, return_counts=True)\n",
    "    print('slice 5: ')\n",
    "    print(dict(zip(unique, counts)))\n",
    "    y_info5 = torch.tensor(y_s5).type(torch.LongTensor)\n",
    "    x_info5 = torch.tensor(df_s5.values).float()\n",
    "\n",
    "\n",
    "    x_data_dict.update({\"x_train0\" : x_info1})\n",
    "    y_data_dict.update({\"y_train0\" : y_info1})\n",
    "\n",
    "    x_data_dict.update({\"x_train1\" : x_info2})\n",
    "    y_data_dict.update({\"y_train1\" : y_info2})\n",
    "\n",
    "    x_data_dict.update({\"x_train2\" : x_info3})\n",
    "    y_data_dict.update({\"y_train2\" : y_info3})\n",
    "\n",
    "    x_data_dict.update({\"x_train3\" : x_info4})\n",
    "    y_data_dict.update({\"y_train3\" : y_info4})\n",
    "\n",
    "    x_data_dict.update({\"x_train4\" : x_info5})\n",
    "    y_data_dict.update({\"y_train4\" : y_info5})\n",
    "    \n",
    "    return x_data_dict, y_data_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da8d839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "slice 1: \n",
      "{0: 7069, 1: 33743}\n",
      "slice 2: \n",
      "{0: 7069, 2: 10430}\n",
      "slice 3: \n",
      "{0: 7069, 3: 5469}\n",
      "slice 4: \n",
      "{0: 7069, 4: 1488}\n",
      "slice 5: \n",
      "{0: 7069}\n",
      "Test set size is : x => (9606, 85) y => (9606,)\n",
      "85 5\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = divide_train_test(df_normalized,propotion=0.1)\n",
    "print(len(df_train))\n",
    "# print('Value counts in train set : ')\n",
    "# df_train['Attack Type'].value_counts()\n",
    "# print('Value counts in test set : ')\n",
    "# print(df_test['Attack Type'].value_counts())\n",
    "\n",
    "x_train_dict, y_train_dict = get_data_for_slices(df_train, number_of_slices, isSmote)\n",
    "\n",
    "df_test = pd.concat(df_test)\n",
    "y_test = df_test.pop('Attack Type').values\n",
    "x_test = df_test.values\n",
    "\n",
    "print('Test set size is : x => ' + str(x_test.shape) + ' y => ' + str(y_test.shape))\n",
    "x_test = torch.tensor(x_test).float()\n",
    "y_test = torch.tensor(y_test.astype('int')).type(torch.LongTensor)\n",
    "\n",
    "inputs = x_test.shape[1]\n",
    "outputs = 5\n",
    "print(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fdb49a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2nn(nn.Module):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        super(Net2nn, self).__init__()\n",
    "        self.fc1=nn.Linear(inputs,200)\n",
    "        self.fc2=nn.Linear(200,200)\n",
    "        self.fc3=nn.Linear(200,outputs)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37778c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WrappedDataLoader:\n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield (self.func(*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f7bef5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    for data, target in train_loader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        prediction = output.argmax(dim=1, keepdim=True)\n",
    "        correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "        \n",
    "\n",
    "    return train_loss / len(train_loader), correct/len(train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a19c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            \n",
    "            test_loss += criterion(output, target).item()\n",
    "            prediction = output.argmax(dim=1, keepdim=True)\n",
    "            correct += prediction.eq(target.view_as(prediction)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    correct /= len(test_loader.dataset)\n",
    "\n",
    "    return (test_loss, correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "89bdf0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_mat(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    # iterate over test data\n",
    "    for inputs, labels in test_loader:\n",
    "        output = model(inputs)  # Feed Network\n",
    "\n",
    "        output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "        y_pred.extend(output)  # Save Prediction\n",
    "\n",
    "        labels = labels.data.cpu().numpy()\n",
    "        y_true.extend(labels)  # Save Truth\n",
    "\n",
    "    cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    precisionv = precision_score(y_true,y_pred,average='macro')\n",
    "    recallv = recall_score(y_true,y_pred,average='macro')\n",
    "    print('precision value: '+str(precisionv))\n",
    "    print('recall value: '+ str(recallv))\n",
    "#     df_cm = pd.DataFrame(cf_matrix, index=[i for i in Counter(y_test)],\n",
    "#                          columns=[i for i in Counter(y_test)])\n",
    "#     plt.figure(1)\n",
    "#     plt.ylabel('True label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "#     plt.figure(figsize=(12, 7))\n",
    "\n",
    "#     sn.heatmap(df_cm, annot=True).set(xlabel='Predicted label', ylabel='True label')\n",
    "#     plt.savefig('D:\\\\learning\\\\PyTorch\\\\experiment\\\\cf\\\\cf_fl_'+str(self.number_of_slices)+'.png')\n",
    "    print('confusion matrix for normal scenario for slices : ' + str(number_of_slices))\n",
    "    print(cf_matrix)\n",
    "    file.write('\\ncf matrix for slice :' + str(number_of_slices))\n",
    "    file.write('\\n'+str(cf_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f880e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_optimizer_criterion_dict(number_of_slices):\n",
    "    model_dict = dict()\n",
    "    optimizer_dict= dict()\n",
    "    criterion_dict = dict()\n",
    "    \n",
    "    for i in range(number_of_slices):\n",
    "        model_name=\"model\"+str(i)\n",
    "        model_info=Net2nn(inputs, outputs)\n",
    "        model_dict.update({model_name : model_info })\n",
    "        \n",
    "        optimizer_name=\"optimizer\"+str(i)\n",
    "        optimizer_info = torch.optim.SGD(model_info.parameters(), lr=learning_rate, momentum=momentum)\n",
    "        optimizer_dict.update({optimizer_name : optimizer_info })\n",
    "        \n",
    "        criterion_name = \"criterion\"+str(i)\n",
    "        criterion_info = nn.CrossEntropyLoss()\n",
    "        criterion_dict.update({criterion_name : criterion_info})\n",
    "        \n",
    "    return model_dict, optimizer_dict, criterion_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "323fad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_weights(model_dict, number_of_slices):\n",
    "   \n",
    "    fc1_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc1.weight.shape)\n",
    "    fc1_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc1.bias.shape)\n",
    "    \n",
    "    fc2_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc2.weight.shape)\n",
    "    fc2_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc2.bias.shape)\n",
    "    \n",
    "    fc3_mean_weight = torch.zeros(size=model_dict[name_of_models[0]].fc3.weight.shape)\n",
    "    fc3_mean_bias = torch.zeros(size=model_dict[name_of_models[0]].fc3.bias.shape)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "    \n",
    "        for i in range(number_of_slices):\n",
    "            fc1_mean_weight += model_dict[name_of_models[i]].fc1.weight.data.clone()\n",
    "            fc1_mean_bias += model_dict[name_of_models[i]].fc1.bias.data.clone()\n",
    "        \n",
    "            fc2_mean_weight += model_dict[name_of_models[i]].fc2.weight.data.clone()\n",
    "            fc2_mean_bias += model_dict[name_of_models[i]].fc2.bias.data.clone()\n",
    "        \n",
    "            fc3_mean_weight += model_dict[name_of_models[i]].fc3.weight.data.clone()\n",
    "            fc3_mean_bias += model_dict[name_of_models[i]].fc3.bias.data.clone()\n",
    "\n",
    "        \n",
    "        fc1_mean_weight =fc1_mean_weight/number_of_slices\n",
    "        fc1_mean_bias = fc1_mean_bias/ number_of_slices\n",
    "    \n",
    "        fc2_mean_weight =fc2_mean_weight/number_of_slices\n",
    "        fc2_mean_bias = fc2_mean_bias/ number_of_slices\n",
    "    \n",
    "        fc3_mean_weight =fc3_mean_weight/number_of_slices\n",
    "        fc3_mean_bias = fc3_mean_bias/ number_of_slices\n",
    "    \n",
    "    return fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061de023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_slices):\n",
    "    fc1_mean_weight, fc1_mean_bias, fc2_mean_weight, fc2_mean_bias, fc3_mean_weight, fc3_mean_bias = get_averaged_weights(model_dict, number_of_slices=number_of_slices)\n",
    "    with torch.no_grad():\n",
    "        main_model.fc1.weight.data = fc1_mean_weight.data.clone()\n",
    "        main_model.fc2.weight.data = fc2_mean_weight.data.clone()\n",
    "        main_model.fc3.weight.data = fc3_mean_weight.data.clone()\n",
    "\n",
    "        main_model.fc1.bias.data = fc1_mean_bias.data.clone()\n",
    "        main_model.fc2.bias.data = fc2_mean_bias.data.clone()\n",
    "        main_model.fc3.bias.data = fc3_mean_bias.data.clone() \n",
    "    return main_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87a60def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_local_and_merged_model_performance(number_of_slices):\n",
    "    accuracy_table=pd.DataFrame(data=np.zeros((number_of_slices,3)), columns=[\"sample\", \"local_ind_model\", \"merged_main_model\"])\n",
    "    for i in range (number_of_slices):\n",
    "    \n",
    "        test_ds = TensorDataset(x_test, y_test)\n",
    "        test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        individual_loss, individual_accuracy = validation(model, test_dl, criterion)\n",
    "        main_loss, main_accuracy =validation(main_model, test_dl, main_criterion )\n",
    "    \n",
    "        accuracy_table.loc[i, \"sample\"]=\"sample \"+str(i)\n",
    "        accuracy_table.loc[i, \"local_ind_model\"] = individual_accuracy\n",
    "        accuracy_table.loc[i, \"merged_main_model\"] = main_accuracy\n",
    "\n",
    "    return accuracy_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "886cf94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_slices):\n",
    "    with torch.no_grad():\n",
    "        for i in range(number_of_slices):\n",
    "            print('Updating model :' + name_of_models[i] )\n",
    "            model_dict[name_of_models[i]].fc1.weight.data =main_model.fc1.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.weight.data =main_model.fc2.weight.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.weight.data =main_model.fc3.weight.data.clone() \n",
    "            \n",
    "            model_dict[name_of_models[i]].fc1.bias.data =main_model.fc1.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc2.bias.data =main_model.fc2.bias.data.clone()\n",
    "            model_dict[name_of_models[i]].fc3.bias.data =main_model.fc3.bias.data.clone() \n",
    "    \n",
    "    return model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f476a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process(number_of_slices):\n",
    "    for i in range (number_of_slices): \n",
    "\n",
    "        print('Federated learning for slice '+ str(i+1))\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "#         valid_ds = TensorDataset(x_valid_dict[name_of_x_valid_sets[i]], y_valid_dict[name_of_y_valid_sets[i]])\n",
    "#         valid_dl = DataLoader(valid_ds, batch_size=batch_size * 2)\n",
    "        \n",
    "        test_ds = TensorDataset(x_test_dict[name_of_x_test_sets[i]], y_test_dict[name_of_y_test_sets[i]])\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        print(\"Subset\" ,i)\n",
    "        for epoch in range(numEpoch):        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "#             valid_loss, valid_accuracy = validation(model, valid_dl, criterion)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "    \n",
    "            print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.5f}\".format(train_accuracy) + \" | test accuracy: {:7.5f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0894528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_train_end_node_process_without_print(number_of_slices):\n",
    "    for i in range (number_of_slices): \n",
    "\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_ds = TensorDataset(x_test, y_test)\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        for epoch in range(numEpoch):        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e5c8a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_train_end_node_process_print_some(number_of_slices, print_amount):\n",
    "    for i in range (number_of_slices): \n",
    "        \n",
    "        print('Federated learning for slice '+ str(i+1))\n",
    "        train_ds = TensorDataset(x_train_dict[name_of_x_train_sets[i]], \n",
    "                                 y_train_dict[name_of_y_train_sets[i]])\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        test_ds = TensorDataset(x_test, y_test)\n",
    "        test_dl = DataLoader(test_ds, batch_size= batch_size * 2)\n",
    "    \n",
    "        model=model_dict[name_of_models[i]]\n",
    "        criterion=criterion_dict[name_of_criterions[i]]\n",
    "        optimizer=optimizer_dict[name_of_optimizers[i]]\n",
    "    \n",
    "        if i<print_amount:\n",
    "            print(\"Subset\" ,i)\n",
    "            \n",
    "        for epoch in range(numEpoch):\n",
    "        \n",
    "            train_loss, train_accuracy = train(model, train_dl, criterion, optimizer)\n",
    "            test_loss, test_accuracy = validation(model, test_dl, criterion)\n",
    "            \n",
    "            if i<print_amount:        \n",
    "                print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.5f}\".format(train_accuracy) + \" | test accuracy: {:7.5f}\".format(test_accuracy))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "543b83bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_model = Net2nn()\n",
    "# initial_optimizer = torch.optim.SGD(initial_model.parameters(), lr=0.01, momentum=0.9)\n",
    "# initial_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "centralized_model = Net2nn(inputs, outputs)\n",
    "centralized_optimizer = torch.optim.SGD(centralized_model.parameters(), lr=0.01, momentum=0.9)\n",
    "centralized_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a9177cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Centralized Model ------\n",
      "Training with slice 1 data\n",
      "epoch:   1 | train accuracy:  0.9614 | test accuracy:  0.7778\n",
      "epoch:   2 | train accuracy:  0.9943 | test accuracy:  0.7844\n",
      "epoch:   3 | train accuracy:  0.9946 | test accuracy:  0.7934\n",
      "epoch:   4 | train accuracy:  0.9954 | test accuracy:  0.7941\n",
      "epoch:   5 | train accuracy:  0.9957 | test accuracy:  0.7921\n",
      "epoch:   6 | train accuracy:  0.9957 | test accuracy:  0.7953\n",
      "epoch:   7 | train accuracy:  0.9958 | test accuracy:  0.7934\n",
      "epoch:   8 | train accuracy:  0.9962 | test accuracy:  0.7937\n",
      "epoch:   9 | train accuracy:  0.9956 | test accuracy:  0.7929\n",
      "epoch:  10 | train accuracy:  0.9969 | test accuracy:  0.7933\n",
      "epoch:  11 | train accuracy:  0.9968 | test accuracy:  0.7945\n",
      "epoch:  12 | train accuracy:  0.9971 | test accuracy:  0.7944\n",
      "epoch:  13 | train accuracy:  0.9966 | test accuracy:  0.7962\n",
      "epoch:  14 | train accuracy:  0.9971 | test accuracy:  0.7949\n",
      "epoch:  15 | train accuracy:  0.9970 | test accuracy:  0.7965\n",
      "epoch:  16 | train accuracy:  0.9971 | test accuracy:  0.7958\n",
      "epoch:  17 | train accuracy:  0.9973 | test accuracy:  0.7914\n",
      "epoch:  18 | train accuracy:  0.9975 | test accuracy:  0.7920\n",
      "epoch:  19 | train accuracy:  0.9968 | test accuracy:  0.7965\n",
      "epoch:  20 | train accuracy:  0.9975 | test accuracy:  0.7959\n",
      " | train accuracy:  0.9975 | test accuracy:  0.7959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.3283814574391221\n",
      "recall value: 0.39837524282003595\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3915   12    0    0    0]\n",
      " [  19 3730    0    0    0]\n",
      " [1158    0    0    0    0]\n",
      " [ 607    0    0    0    0]\n",
      " [   2  163    0    0    0]]\n",
      "Training with slice 2 data\n",
      "epoch:   1 | train accuracy:  0.9656 | test accuracy:  0.5219\n",
      "epoch:   2 | train accuracy:  0.9951 | test accuracy:  0.5229\n",
      "epoch:   3 | train accuracy:  0.9955 | test accuracy:  0.5232\n",
      "epoch:   4 | train accuracy:  0.9963 | test accuracy:  0.5236\n",
      "epoch:   5 | train accuracy:  0.9966 | test accuracy:  0.5239\n",
      "epoch:   6 | train accuracy:  0.9974 | test accuracy:  0.5254\n",
      "epoch:   7 | train accuracy:  0.9979 | test accuracy:  0.5269\n",
      "epoch:   8 | train accuracy:  0.9985 | test accuracy:  0.5263\n",
      "epoch:   9 | train accuracy:  0.9985 | test accuracy:  0.5255\n",
      "epoch:  10 | train accuracy:  0.9987 | test accuracy:  0.5275\n",
      "epoch:  11 | train accuracy:  0.9987 | test accuracy:  0.5276\n",
      "epoch:  12 | train accuracy:  0.9987 | test accuracy:  0.5270\n",
      "epoch:  13 | train accuracy:  0.9987 | test accuracy:  0.5264\n",
      "epoch:  14 | train accuracy:  0.9988 | test accuracy:  0.5275\n",
      "epoch:  15 | train accuracy:  0.9990 | test accuracy:  0.5254\n",
      "epoch:  16 | train accuracy:  0.9989 | test accuracy:  0.5272\n",
      "epoch:  17 | train accuracy:  0.9991 | test accuracy:  0.5279\n",
      "epoch:  18 | train accuracy:  0.9989 | test accuracy:  0.5278\n",
      "epoch:  19 | train accuracy:  0.9989 | test accuracy:  0.5270\n",
      "epoch:  20 | train accuracy:  0.9989 | test accuracy:  0.5278\n",
      " | train accuracy:  0.9989 | test accuracy:  0.5278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.24504172781329497\n",
      "recall value: 0.39923605805958745\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3912    0   15    0    0]\n",
      " [3749    0    0    0    0]\n",
      " [   0    0 1158    0    0]\n",
      " [ 212    0  395    0    0]\n",
      " [ 165    0    0    0    0]]\n",
      "Training with slice 3 data\n",
      "epoch:   1 | train accuracy:  0.9576 | test accuracy:  0.4659\n",
      "epoch:   2 | train accuracy:  0.9930 | test accuracy:  0.4660\n",
      "epoch:   3 | train accuracy:  0.9947 | test accuracy:  0.4676\n",
      "epoch:   4 | train accuracy:  0.9957 | test accuracy:  0.4681\n",
      "epoch:   5 | train accuracy:  0.9965 | test accuracy:  0.4687\n",
      "epoch:   6 | train accuracy:  0.9969 | test accuracy:  0.4691\n",
      "epoch:   7 | train accuracy:  0.9970 | test accuracy:  0.4689\n",
      "epoch:   8 | train accuracy:  0.9972 | test accuracy:  0.4696\n",
      "epoch:   9 | train accuracy:  0.9972 | test accuracy:  0.4688\n",
      "epoch:  10 | train accuracy:  0.9978 | test accuracy:  0.4688\n",
      "epoch:  11 | train accuracy:  0.9974 | test accuracy:  0.4704\n",
      "epoch:  12 | train accuracy:  0.9978 | test accuracy:  0.4702\n",
      "epoch:  13 | train accuracy:  0.9981 | test accuracy:  0.4703\n",
      "epoch:  14 | train accuracy:  0.9982 | test accuracy:  0.4701\n",
      "epoch:  15 | train accuracy:  0.9978 | test accuracy:  0.4694\n",
      "epoch:  16 | train accuracy:  0.9983 | test accuracy:  0.4701\n",
      "epoch:  17 | train accuracy:  0.9980 | test accuracy:  0.4697\n",
      "epoch:  18 | train accuracy:  0.9984 | test accuracy:  0.4693\n",
      "epoch:  19 | train accuracy:  0.9982 | test accuracy:  0.4687\n",
      "epoch:  20 | train accuracy:  0.9983 | test accuracy:  0.4704\n",
      " | train accuracy:  0.9983 | test accuracy:  0.4704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.18555192017162633\n",
      "recall value: 0.3984003785728759\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3915    0    0   12    0]\n",
      " [3749    0    0    0    0]\n",
      " [ 446    0    0  712    0]\n",
      " [   3    0    0  604    0]\n",
      " [ 165    0    0    0    0]]\n",
      "Training with slice 4 data\n",
      "epoch:   1 | train accuracy:  0.9500 | test accuracy:  0.4256\n",
      "epoch:   2 | train accuracy:  0.9991 | test accuracy:  0.4258\n",
      "epoch:   3 | train accuracy:  0.9991 | test accuracy:  0.4259\n",
      "epoch:   4 | train accuracy:  0.9995 | test accuracy:  0.4259\n",
      "epoch:   5 | train accuracy:  0.9995 | test accuracy:  0.4259\n",
      "epoch:   6 | train accuracy:  0.9995 | test accuracy:  0.4259\n",
      "epoch:   7 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      "epoch:   8 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      "epoch:   9 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      "epoch:  10 | train accuracy:  0.9996 | test accuracy:  0.4259\n",
      "epoch:  11 | train accuracy:  0.9996 | test accuracy:  0.4259\n",
      "epoch:  12 | train accuracy:  0.9998 | test accuracy:  0.4260\n",
      "epoch:  13 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      "epoch:  14 | train accuracy:  0.9998 | test accuracy:  0.4259\n",
      "epoch:  15 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      "epoch:  16 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      "epoch:  17 | train accuracy:  0.9998 | test accuracy:  0.4260\n",
      "epoch:  18 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      "epoch:  19 | train accuracy:  0.9996 | test accuracy:  0.4259\n",
      "epoch:  20 | train accuracy:  0.9996 | test accuracy:  0.4260\n",
      " | train accuracy:  0.9996 | test accuracy:  0.4260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.28319034000635523\n",
      "recall value: 0.4\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [3749    0    0    0    0]\n",
      " [1158    0    0    0    0]\n",
      " [ 607    0    0    0    0]\n",
      " [   0    0    0    0  165]]\n",
      "Training with slice 5 data\n",
      "epoch:   1 | train accuracy:  0.9873 | test accuracy:  0.4088\n",
      "epoch:   2 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:   3 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:   4 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:   5 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:   6 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:   7 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:   8 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:   9 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  10 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  11 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  12 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  13 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  14 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  15 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  16 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  17 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  18 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  19 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "epoch:  20 | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      " | train accuracy:  1.0000 | test accuracy:  0.4088\n",
      "precision value: 0.08176139912554653\n",
      "recall value: 0.2\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [3749    0    0    0    0]\n",
      " [1158    0    0    0    0]\n",
      " [ 607    0    0    0    0]\n",
      " [ 165    0    0    0    0]]\n",
      "------ Training finished ------\n",
      "Mean train accuracy: 0.9965427125558606\n",
      "Mean test accuracy: 0.5245138455132211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"------ Centralized Model ------\")\n",
    "\n",
    "train_acc = []\n",
    "test_acc = []\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "\n",
    "test_ds = TensorDataset(x_test, y_test)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size * 2)\n",
    "\n",
    "for i in range(number_of_slices):\n",
    "    centralized_model = Net2nn(inputs,outputs)\n",
    "    centralized_optimizer = torch.optim.SGD(centralized_model.parameters(), lr=0.01, momentum=0.9)\n",
    "    centralized_criterion = nn.CrossEntropyLoss()\n",
    "#     centralized_model = copy.deepcopy(initial_model)\n",
    "#     centralized_optimizer = copy.deepcopy(initial_optimizer)\n",
    "#     centralized_criterion = copy.deepcopy(initial_criterion)\n",
    "    print('Training with slice ' + str(i+1) + ' data' )\n",
    "    x_name = 'x_train' + str(i)\n",
    "    y_name = 'y_train' + str(i)\n",
    "    train_ds = TensorDataset(x_train_dict[x_name], y_train_dict[y_name])\n",
    "    train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(numEpoch):\n",
    "        central_train_loss, central_train_accuracy = train(centralized_model, train_dl, centralized_criterion, centralized_optimizer)\n",
    "        central_test_loss, central_test_accuracy = validation(centralized_model, test_dl, centralized_criterion)\n",
    "        \n",
    "        train_acc.append(central_train_accuracy)\n",
    "        train_loss.append(central_train_loss)\n",
    "        test_acc.append(central_test_accuracy)\n",
    "        test_loss.append(central_test_loss)\n",
    "        \n",
    "        print(\"epoch: {:3.0f}\".format(epoch+1) + \" | train accuracy: {:7.4f}\".format(central_train_accuracy) + \" | test accuracy: {:7.4f}\".format(central_test_accuracy))\n",
    "    print(\" | train accuracy: {:7.4f}\".format(central_train_accuracy) + \" | test accuracy: {:7.4f}\".format(central_test_accuracy))\n",
    "    confusion_mat(centralized_model, test_dl)\n",
    "    \n",
    "print(\"------ Training finished ------\")\n",
    "print('Mean train accuracy: ' + str(sum(train_acc)/len(train_acc)))\n",
    "print('Mean test accuracy: ' + str(sum(test_acc)/len(test_acc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f3b92e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.write('\\nCentralized Mean train accuracy: ' + str(sum(train_acc)/len(train_acc)))\n",
    "file.write('\\nCentralized Mean test accuracy: ' + str(sum(test_acc)/len(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9851821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([17499, 85]) torch.Size([17499])\n",
      "torch.Size([9606, 85]) torch.Size([9606])\n"
     ]
    }
   ],
   "source": [
    "print(x_train_dict[\"x_train1\"].shape, y_train_dict[\"y_train1\"].shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5961c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_model = Net2nn(inputs,outputs)\n",
    "main_optimizer = torch.optim.SGD(main_model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "main_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49f5495c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict, optimizer_dict, criterion_dict = create_model_optimizer_criterion_dict(number_of_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59415549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x_train0', 'x_train1', 'x_train2', 'x_train3', 'x_train4']\n",
      "['y_train0', 'y_train1', 'y_train2', 'y_train3', 'y_train4']\n",
      "\n",
      " ------------\n",
      "['model0', 'model1', 'model2', 'model3', 'model4']\n",
      "['optimizer0', 'optimizer1', 'optimizer2', 'optimizer3', 'optimizer4']\n",
      "['criterion0', 'criterion1', 'criterion2', 'criterion3', 'criterion4']\n"
     ]
    }
   ],
   "source": [
    "name_of_x_train_sets=list(x_train_dict.keys())\n",
    "name_of_y_train_sets=list(y_train_dict.keys())\n",
    "\n",
    "name_of_models=list(model_dict.keys())\n",
    "name_of_optimizers=list(optimizer_dict.keys())\n",
    "name_of_criterions=list(criterion_dict.keys())\n",
    "\n",
    "print(name_of_x_train_sets)\n",
    "print(name_of_y_train_sets)\n",
    "print(\"\\n ------------\")\n",
    "print(name_of_models)\n",
    "print(name_of_optimizers)\n",
    "print(name_of_criterions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17d7afff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0700,  0.0199,  0.0060,  0.0049, -0.0007]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[ 0.0313, -0.0698, -0.0490,  0.0331, -0.0566]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(main_model.fc2.weight[0:1,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0:1,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6464bd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n"
     ]
    }
   ],
   "source": [
    "model_dict=send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec2e1051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0700,  0.0199,  0.0060,  0.0049, -0.0007]],\n",
      "       grad_fn=<SliceBackward>)\n",
      "tensor([[-0.0700,  0.0199,  0.0060,  0.0049, -0.0007]],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(main_model.fc2.weight[0:1,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0:1,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7689e7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated learning for slice 1\n",
      "Subset 0\n",
      "epoch:   1 | train accuracy: 0.96099 | test accuracy: 0.78441\n",
      "epoch:   2 | train accuracy: 0.99373 | test accuracy: 0.79471\n",
      "epoch:   3 | train accuracy: 0.99471 | test accuracy: 0.78940\n",
      "epoch:   4 | train accuracy: 0.99476 | test accuracy: 0.77358\n",
      "epoch:   5 | train accuracy: 0.99473 | test accuracy: 0.79315\n",
      "epoch:   6 | train accuracy: 0.99581 | test accuracy: 0.79065\n",
      "epoch:   7 | train accuracy: 0.99468 | test accuracy: 0.79211\n",
      "epoch:   8 | train accuracy: 0.99613 | test accuracy: 0.79138\n",
      "epoch:   9 | train accuracy: 0.99571 | test accuracy: 0.79263\n",
      "epoch:  10 | train accuracy: 0.99625 | test accuracy: 0.79398\n",
      "epoch:  11 | train accuracy: 0.99598 | test accuracy: 0.79513\n",
      "epoch:  12 | train accuracy: 0.99674 | test accuracy: 0.79315\n",
      "epoch:  13 | train accuracy: 0.99686 | test accuracy: 0.79305\n",
      "epoch:  14 | train accuracy: 0.99667 | test accuracy: 0.79502\n",
      "epoch:  15 | train accuracy: 0.99713 | test accuracy: 0.79450\n",
      "epoch:  16 | train accuracy: 0.99659 | test accuracy: 0.79638\n",
      "epoch:  17 | train accuracy: 0.99679 | test accuracy: 0.79544\n",
      "epoch:  18 | train accuracy: 0.99708 | test accuracy: 0.79346\n",
      "epoch:  19 | train accuracy: 0.99723 | test accuracy: 0.79565\n",
      "epoch:  20 | train accuracy: 0.99745 | test accuracy: 0.79565\n",
      "Federated learning for slice 2\n",
      "Subset 1\n",
      "epoch:   1 | train accuracy: 0.95783 | test accuracy: 0.52186\n",
      "epoch:   2 | train accuracy: 0.99497 | test accuracy: 0.52290\n",
      "epoch:   3 | train accuracy: 0.99549 | test accuracy: 0.52353\n",
      "epoch:   4 | train accuracy: 0.99617 | test accuracy: 0.52415\n",
      "epoch:   5 | train accuracy: 0.99697 | test accuracy: 0.52467\n",
      "epoch:   6 | train accuracy: 0.99754 | test accuracy: 0.52509\n",
      "epoch:   7 | train accuracy: 0.99800 | test accuracy: 0.52540\n",
      "epoch:   8 | train accuracy: 0.99840 | test accuracy: 0.52655\n",
      "epoch:   9 | train accuracy: 0.99851 | test accuracy: 0.52623\n",
      "epoch:  10 | train accuracy: 0.99846 | test accuracy: 0.52738\n",
      "epoch:  11 | train accuracy: 0.99874 | test accuracy: 0.52675\n",
      "epoch:  12 | train accuracy: 0.99869 | test accuracy: 0.52665\n",
      "epoch:  13 | train accuracy: 0.99880 | test accuracy: 0.52603\n",
      "epoch:  14 | train accuracy: 0.99886 | test accuracy: 0.52665\n",
      "epoch:  15 | train accuracy: 0.99891 | test accuracy: 0.52655\n",
      "epoch:  16 | train accuracy: 0.99880 | test accuracy: 0.52759\n",
      "epoch:  17 | train accuracy: 0.99880 | test accuracy: 0.52707\n",
      "epoch:  18 | train accuracy: 0.99891 | test accuracy: 0.52717\n",
      "epoch:  19 | train accuracy: 0.99891 | test accuracy: 0.52800\n",
      "epoch:  20 | train accuracy: 0.99886 | test accuracy: 0.52790\n",
      "Federated learning for slice 3\n",
      "Subset 2\n",
      "epoch:   1 | train accuracy: 0.94249 | test accuracy: 0.46585\n",
      "epoch:   2 | train accuracy: 0.99322 | test accuracy: 0.46658\n",
      "epoch:   3 | train accuracy: 0.99442 | test accuracy: 0.46762\n",
      "epoch:   4 | train accuracy: 0.99561 | test accuracy: 0.46742\n",
      "epoch:   5 | train accuracy: 0.99609 | test accuracy: 0.46960\n",
      "epoch:   6 | train accuracy: 0.99649 | test accuracy: 0.46898\n",
      "epoch:   7 | train accuracy: 0.99697 | test accuracy: 0.47002\n",
      "epoch:   8 | train accuracy: 0.99721 | test accuracy: 0.46887\n",
      "epoch:   9 | train accuracy: 0.99761 | test accuracy: 0.47002\n",
      "epoch:  10 | train accuracy: 0.99793 | test accuracy: 0.46919\n",
      "epoch:  11 | train accuracy: 0.99801 | test accuracy: 0.46929\n",
      "epoch:  12 | train accuracy: 0.99801 | test accuracy: 0.46835\n",
      "epoch:  13 | train accuracy: 0.99769 | test accuracy: 0.47002\n",
      "epoch:  14 | train accuracy: 0.99745 | test accuracy: 0.47044\n",
      "epoch:  15 | train accuracy: 0.99833 | test accuracy: 0.47044\n",
      "epoch:  16 | train accuracy: 0.99825 | test accuracy: 0.46939\n",
      "epoch:  17 | train accuracy: 0.99833 | test accuracy: 0.46981\n",
      "epoch:  18 | train accuracy: 0.99833 | test accuracy: 0.47002\n",
      "epoch:  19 | train accuracy: 0.99864 | test accuracy: 0.47012\n",
      "epoch:  20 | train accuracy: 0.99801 | test accuracy: 0.46991\n",
      "Federated learning for slice 4\n",
      "Federated learning for slice 5\n"
     ]
    }
   ],
   "source": [
    "# start_train_end_node_process()\n",
    "start_train_end_node_process_print_some(number_of_slices, print_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23bec51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0700,  0.0199,  0.0060,  0.0049, -0.0007], grad_fn=<SliceBackward>)\n",
      "tensor([-0.0713,  0.0199,  0.0057,  0.0047, -0.0008], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "## As you can see, wieghts of local models are updated after training process\n",
    "print(main_model.fc2.weight[0,0:5])\n",
    "print(model_dict[\"model1\"].fc2.weight[0,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "06336116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.009179062636000861\n",
      "recall value: 0.085948880076218\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[  12   42    0 3872    1]\n",
      " [   0    0    0 3749    0]\n",
      " [ 615   24    0  518    1]\n",
      " [ 139  209    0  259    0]\n",
      " [   1    0    0  164    0]]\n",
      "precision value: 0.08176139912554653\n",
      "recall value: 0.2\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [3749    0    0    0    0]\n",
      " [1158    0    0    0    0]\n",
      " [ 607    0    0    0    0]\n",
      " [ 165    0    0    0    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "before_acc_table=compare_local_and_merged_model_performance(number_of_slices=number_of_slices)\n",
    "before_test_loss, before_test_accuracy = validation(main_model, test_dl, main_criterion)\n",
    "file.write('\\nbefore training main model')\n",
    "confusion_mat(main_model, test_dl)\n",
    "\n",
    "main_model= set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_slices) \n",
    "\n",
    "after_acc_table=compare_local_and_merged_model_performance(number_of_slices=number_of_slices)\n",
    "after_test_loss, after_test_accuracy = validation(main_model, test_dl, main_criterion)\n",
    "file.write('\\nafter training main model')\n",
    "confusion_mat(main_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f992e8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated main model vs individual local models before FedAvg first iteration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>local_ind_model</th>\n",
       "      <th>merged_main_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample 0</td>\n",
       "      <td>0.7956</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample 1</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample 2</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample 3</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample 4</td>\n",
       "      <td>0.4088</td>\n",
       "      <td>0.0282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample  local_ind_model  merged_main_model\n",
       "0  sample 0           0.7956             0.0282\n",
       "1  sample 1           0.5279             0.0282\n",
       "2  sample 2           0.4699             0.0282\n",
       "3  sample 3           0.4260             0.0282\n",
       "4  sample 4           0.4088             0.0282"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Federated main model vs individual local models before FedAvg first iteration\")\n",
    "file.write('\\nBefore training federated')\n",
    "file.write('\\n'+str(before_acc_table))\n",
    "before_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f5ff331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Federated main model vs individual local models after FedAvg first iteration\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>local_ind_model</th>\n",
       "      <th>merged_main_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample 0</td>\n",
       "      <td>0.7956</td>\n",
       "      <td>0.4088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample 1</td>\n",
       "      <td>0.5279</td>\n",
       "      <td>0.4088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample 2</td>\n",
       "      <td>0.4699</td>\n",
       "      <td>0.4088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample 3</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>0.4088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample 4</td>\n",
       "      <td>0.4088</td>\n",
       "      <td>0.4088</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample  local_ind_model  merged_main_model\n",
       "0  sample 0           0.7956             0.4088\n",
       "1  sample 1           0.5279             0.4088\n",
       "2  sample 2           0.4699             0.4088\n",
       "3  sample 3           0.4260             0.4088\n",
       "4  sample 4           0.4088             0.4088"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Federated main model vs individual local models after FedAvg first iteration\")\n",
    "file.write('\\nAfter training federated')\n",
    "file.write('\\n'+str(after_acc_table))\n",
    "after_acc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e66d749d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 1st iteration main model accuracy on all test data:  0.0282\n",
      "After 1st iteration main model accuracy on all test data:  0.4088\n",
      "Centralized model accuracy on all test data:  0.4088\n"
     ]
    }
   ],
   "source": [
    "print(\"Before 1st iteration main model accuracy on all test data: {:7.4f}\".format(before_test_accuracy))\n",
    "print(\"After 1st iteration main model accuracy on all test data: {:7.4f}\".format(after_test_accuracy))\n",
    "print(\"Centralized model accuracy on all test data: {:7.4f}\".format(central_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93b08114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 2 : main_model accuracy on all test data:  0.4695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.2140338554334079\n",
      "recall value: 0.3010561926136446\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3924    0    3    0    0]\n",
      " [3749    0    0    0    0]\n",
      " [ 572    0  586    0    0]\n",
      " [ 246    0  361    0    0]\n",
      " [ 165    0    0    0    0]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 3 : main_model accuracy on all test data:  0.4088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.08176139912554653\n",
      "recall value: 0.2\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [3749    0    0    0    0]\n",
      " [1158    0    0    0    0]\n",
      " [ 607    0    0    0    0]\n",
      " [ 165    0    0    0    0]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 4 : main_model accuracy on all test data:  0.4329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.3996232662890782\n",
      "recall value: 0.24224803885583562\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [3749    0    0    0    0]\n",
      " [ 941    0  216    1    0]\n",
      " [ 468    0  124   15    0]\n",
      " [ 148   17    0    0    0]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 5 : main_model accuracy on all test data:  0.4351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.5405808397560923\n",
      "recall value: 0.22166894336001358\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [3529  220    0    0    0]\n",
      " [1151    0    6    1    0]\n",
      " [ 569    0   11   27    0]\n",
      " [ 157    8    0    0    0]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 6 : main_model accuracy on all test data:  0.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.6133499057683712\n",
      "recall value: 0.31320584577671606\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [3016  733    0    0    0]\n",
      " [ 911    0  244    3    0]\n",
      " [ 444    0   66   97    0]\n",
      " [  23  142    0    0    0]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 7 : main_model accuracy on all test data:  0.6128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares\\anaconda-python\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.6345331334083901\n",
      "recall value: 0.40906200682650606\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [2344 1405    0    0    0]\n",
      " [ 802    0  311   45    0]\n",
      " [ 327    0   36  244    0]\n",
      " [  13  152    0    0    0]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 8 : main_model accuracy on all test data:  0.5937\n",
      "precision value: 0.8403758869504518\n",
      "recall value: 0.4665793998927318\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [2603 1146    0    0    0]\n",
      " [ 796    0  312   50    0]\n",
      " [ 319    0   23  265    0]\n",
      " [   7  105    0    0   53]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 9 : main_model accuracy on all test data:  0.6279\n",
      "precision value: 0.8600919890031327\n",
      "recall value: 0.5169856146197824\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [2274 1475    0    0    0]\n",
      " [ 804    0  322   32    0]\n",
      " [ 371    0   20  216    0]\n",
      " [   5   68    0    0   92]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 10 : main_model accuracy on all test data:  0.6989\n",
      "precision value: 0.8810525717639287\n",
      "recall value: 0.6944493020226086\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [2101 1648    0    0    0]\n",
      " [ 434    0  692   32    0]\n",
      " [ 260    0   57  290    0]\n",
      " [   7    0    0    0  158]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 11 : main_model accuracy on all test data:  0.7545\n",
      "precision value: 0.8897267600612736\n",
      "recall value: 0.662609042509429\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3927    0    0    0    0]\n",
      " [1196 2553    0    0    0]\n",
      " [ 765    0  354   39    0]\n",
      " [ 320    0   19  268    0]\n",
      " [   5   14    0    0  146]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 12 : main_model accuracy on all test data:  0.7523\n",
      "precision value: 0.8905992214502388\n",
      "recall value: 0.7289634469520305\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1629 2120    0    0    0]\n",
      " [ 398    0  713   47    0]\n",
      " [ 265    0   31  311    0]\n",
      " [   2    6    0    0  157]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 13 : main_model accuracy on all test data:  0.7835\n",
      "precision value: 0.896101969758244\n",
      "recall value: 0.752033241444372\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1321 2428    0    0    0]\n",
      " [ 432    0  663   63    0]\n",
      " [ 239    0   18  350    0]\n",
      " [   2    4    0    0  159]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 14 : main_model accuracy on all test data:  0.7586\n",
      "precision value: 0.889865683486654\n",
      "recall value: 0.742541085079474\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1605 2144    0    0    0]\n",
      " [ 357    0  744   57    0]\n",
      " [ 274    0   23  310    0]\n",
      " [   2    0    0    0  163]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 15 : main_model accuracy on all test data:  0.8140\n",
      "precision value: 0.9111336253452429\n",
      "recall value: 0.7995766208012811\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1141 2608    0    0    0]\n",
      " [ 423    0  681   54    0]\n",
      " [ 145    0   21  441    0]\n",
      " [   2    0    0    0  163]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 16 : main_model accuracy on all test data:  0.8326\n",
      "precision value: 0.9100715065196223\n",
      "recall value: 0.8116527955695171\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1027 2722    0    0    0]\n",
      " [ 299    0  785   74    0]\n",
      " [ 196    0   10  401    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 17 : main_model accuracy on all test data:  0.8099\n",
      "precision value: 0.9086159690898878\n",
      "recall value: 0.8126382733804964\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1264 2485    0    0    0]\n",
      " [ 349    0  738   71    0]\n",
      " [ 128    0   12  467    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 18 : main_model accuracy on all test data:  0.8327\n",
      "precision value: 0.9106327655846507\n",
      "recall value: 0.8163987533171824\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1064 2685    0    0    0]\n",
      " [ 265    0  822   71    0]\n",
      " [ 192    0   13  402    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 19 : main_model accuracy on all test data:  0.8505\n",
      "precision value: 0.9217820023413414\n",
      "recall value: 0.8398823553027441\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 924 2825    0    0    0]\n",
      " [ 315    0  785   58    0]\n",
      " [ 119    0   18  470    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 20 : main_model accuracy on all test data:  0.8115\n",
      "precision value: 0.9061572184883777\n",
      "recall value: 0.8088295519969402\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1280 2469    0    0    0]\n",
      " [ 270    0  822   66    0]\n",
      " [ 172    0   21  414    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 21 : main_model accuracy on all test data:  0.8346\n",
      "precision value: 0.9128809001569268\n",
      "recall value: 0.8210931831054669\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1030 2719    0    0    0]\n",
      " [ 315    0  770   73    0]\n",
      " [ 158    0   11  438    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 22 : main_model accuracy on all test data:  0.9049\n",
      "precision value: 0.9364007727524666\n",
      "recall value: 0.872723426241887\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 499 3250    0    0    0]\n",
      " [ 181    0  924   53    0]\n",
      " [ 149    0   30  428    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 23 : main_model accuracy on all test data:  0.8894\n",
      "precision value: 0.9313884927326199\n",
      "recall value: 0.8728094053951974\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 639 3110    0    0    0]\n",
      " [ 231    0  859   68    0]\n",
      " [ 105    0   17  485    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 24 : main_model accuracy on all test data:  0.8626\n",
      "precision value: 0.9259208984096208\n",
      "recall value: 0.8700878058532396\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 979 2770    0    0    0]\n",
      " [ 166    0  933   59    0]\n",
      " [  93    0   21  493    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 25 : main_model accuracy on all test data:  0.9255\n",
      "precision value: 0.9455226159815311\n",
      "recall value: 0.9105423241809285\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 398 3351    0    0    0]\n",
      " [ 166    0  921   71    0]\n",
      " [  66    0   13  528    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 26 : main_model accuracy on all test data:  0.8475\n",
      "precision value: 0.921094246721837\n",
      "recall value: 0.8624593272407793\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1096 2653    0    0    0]\n",
      " [ 206    0  883   69    0]\n",
      " [  79    0   13  515    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 27 : main_model accuracy on all test data:  0.9179\n",
      "precision value: 0.9391624950622217\n",
      "recall value: 0.9091403508282161\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 484 3265    0    0    0]\n",
      " [ 141    0  928   89    0]\n",
      " [  63    0   10  534    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 28 : main_model accuracy on all test data:  0.8571\n",
      "precision value: 0.9244261718233389\n",
      "recall value: 0.8694178595790556\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1033 2716    0    0    0]\n",
      " [ 176    0  921   61    0]\n",
      " [  81    0   20  506    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 29 : main_model accuracy on all test data:  0.9242\n",
      "precision value: 0.9434051120861812\n",
      "recall value: 0.9139605298878276\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 444 3305    0    0    0]\n",
      " [ 127    0  955   76    0]\n",
      " [  63    0   16  528    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 30 : main_model accuracy on all test data:  0.8699\n",
      "precision value: 0.9269555860799914\n",
      "recall value: 0.8828154481595671\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 941 2808    0    0    0]\n",
      " [ 156    0  932   70    0]\n",
      " [  64    0   17  526    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 31 : main_model accuracy on all test data:  0.9408\n",
      "precision value: 0.9553485923949875\n",
      "recall value: 0.92555337903436\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 315 3434    0    0    0]\n",
      " [ 120    0  988   50    0]\n",
      " [  59    0   23  525    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 32 : main_model accuracy on all test data:  0.8807\n",
      "precision value: 0.9305071647821285\n",
      "recall value: 0.8799314867939421\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 790 2959    0    0    0]\n",
      " [ 188    0  903   67    0]\n",
      " [  84    0   15  508    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 33 : main_model accuracy on all test data:  0.9519\n",
      "precision value: 0.954097419341986\n",
      "recall value: 0.9233835430711947\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 142 3607    0    0    0]\n",
      " [ 157    0  922   79    0]\n",
      " [  72    0   10  525    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 34 : main_model accuracy on all test data:  0.8764\n",
      "precision value: 0.9315840835621462\n",
      "recall value: 0.8820413413043676\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 867 2882    0    0    0]\n",
      " [ 160    0  939   59    0]\n",
      " [  84    0   15  508    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 35 : main_model accuracy on all test data:  0.9579\n",
      "precision value: 0.956728102449166\n",
      "recall value: 0.9430568527076215\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 194 3555    0    0    0]\n",
      " [  68    0 1010   80    0]\n",
      " [  45    0   15  547    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 36 : main_model accuracy on all test data:  0.8465\n",
      "precision value: 0.9222563971844739\n",
      "recall value: 0.8803845362206213\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1237 2512    0    0    0]\n",
      " [  97    0  996   65    0]\n",
      " [  57    0   17  533    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 37 : main_model accuracy on all test data:  0.9725\n",
      "precision value: 0.9550416916898399\n",
      "recall value: 0.9578296568014913\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3922    4    0    1    0]\n",
      " [  63 3686    0    0    0]\n",
      " [  36    0  992  130    0]\n",
      " [  21    0    9  577    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 38 : main_model accuracy on all test data:  0.8793\n",
      "precision value: 0.9347081755806993\n",
      "recall value: 0.895384200264407\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 912 2837    0    0    0]\n",
      " [ 116    0  992   50    0]\n",
      " [  57    0   22  528    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 39 : main_model accuracy on all test data:  0.9431\n",
      "precision value: 0.9487171331268014\n",
      "recall value: 0.9409374885637888\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 360 3389    0    0    0]\n",
      " [  45    0 1021   92    0]\n",
      " [  36    0   13  558    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 40 : main_model accuracy on all test data:  0.8724\n",
      "precision value: 0.9290443171723826\n",
      "recall value: 0.8969514884674883\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1005 2744    0    0    0]\n",
      " [  85    0 1005   68    0]\n",
      " [  49    0   17  541    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 41 : main_model accuracy on all test data:  0.9601\n",
      "precision value: 0.9597714299959194\n",
      "recall value: 0.9444532931862029\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 174 3575    0    0    0]\n",
      " [  78    0 1010   70    0]\n",
      " [  42    0   17  548    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 42 : main_model accuracy on all test data:  0.8588\n",
      "precision value: 0.9245491074771774\n",
      "recall value: 0.8931732288191612\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1147 2602    0    0    0]\n",
      " [  80    0 1006   72    0]\n",
      " [  38    0   17  552    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 43 : main_model accuracy on all test data:  0.9634\n",
      "precision value: 0.9600413808592856\n",
      "recall value: 0.9480471825413052\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 154 3595    0    0    0]\n",
      " [  65    0 1017   76    0]\n",
      " [  39    0   16  552    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 44 : main_model accuracy on all test data:  0.8785\n",
      "precision value: 0.9332968229652187\n",
      "recall value: 0.902008818666307\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 962 2787    0    0    0]\n",
      " [  78    0 1021   59    0]\n",
      " [  49    0   17  541    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45 : main_model accuracy on all test data:  0.9594\n",
      "precision value: 0.9624259658478435\n",
      "recall value: 0.934639381887628\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 140 3609    0    0    0]\n",
      " [ 109    0  998   51    0]\n",
      " [  65    0   23  519    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 46 : main_model accuracy on all test data:  0.8825\n",
      "precision value: 0.9349201662824214\n",
      "recall value: 0.9029831184792491\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 927 2822    0    0    0]\n",
      " [  73    0 1033   52    0]\n",
      " [  50    0   25  532    0]\n",
      " [   1    0    0    0  164]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 47 : main_model accuracy on all test data:  0.9502\n",
      "precision value: 0.9599790314246393\n",
      "recall value: 0.94068478138174\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 283 3466    0    0    0]\n",
      " [  76    0 1032   50    0]\n",
      " [  47    0   21  539    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 48 : main_model accuracy on all test data:  0.9011\n",
      "precision value: 0.9406221540374984\n",
      "recall value: 0.9201385611810469\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 782 2967    0    0    0]\n",
      " [  51    0 1050   57    0]\n",
      " [  38    0   21  548    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 49 : main_model accuracy on all test data:  0.9451\n",
      "precision value: 0.9520123748725613\n",
      "recall value: 0.9404527075905321\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 327 3422    0    0    0]\n",
      " [  71    0 1008   79    0]\n",
      " [  33    0   16  558    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 50 : main_model accuracy on all test data:  0.9052\n",
      "precision value: 0.9378832191596024\n",
      "recall value: 0.9153405398778809\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 688 3061    0    0    0]\n",
      " [  86    0  997   75    0]\n",
      " [  45    0   16  546    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 51 : main_model accuracy on all test data:  0.9491\n",
      "precision value: 0.9523125963707733\n",
      "recall value: 0.934405899344841\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 245 3504    0    0    0]\n",
      " [  95    0  982   81    0]\n",
      " [  51    0   16  540    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 52 : main_model accuracy on all test data:  0.8908\n",
      "precision value: 0.9326006684704758\n",
      "recall value: 0.9098884008849151\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 842 2907    0    0    0]\n",
      " [  68    0 1013   77    0]\n",
      " [  44    0   17  546    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 53 : main_model accuracy on all test data:  0.9626\n",
      "precision value: 0.9568671246116175\n",
      "recall value: 0.9489002278042898\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 156 3593    0    0    0]\n",
      " [  62    0 1006   90    0]\n",
      " [  35    0   15  557    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 54 : main_model accuracy on all test data:  0.8888\n",
      "precision value: 0.9335965540833788\n",
      "recall value: 0.9125537129707822\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 880 2869    0    0    0]\n",
      " [  63    0 1023   72    0]\n",
      " [  35    0   17  555    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 55 : main_model accuracy on all test data:  0.9750\n",
      "precision value: 0.9608905427601708\n",
      "recall value: 0.9593866273944318\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3924    2    0    1    0]\n",
      " [  67 3682    0    0    0]\n",
      " [  25    0 1036   97    0]\n",
      " [  32    0   16  559    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 56 : main_model accuracy on all test data:  0.9008\n",
      "precision value: 0.9368262919734647\n",
      "recall value: 0.9221805294714539\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 789 2960    0    0    0]\n",
      " [  39    0 1043   76    0]\n",
      " [  32    0   16  559    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 57 : main_model accuracy on all test data:  0.9496\n",
      "precision value: 0.9496750496901173\n",
      "recall value: 0.9480218371134199\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 319 3430    0    0    0]\n",
      " [  22    0 1036  100    0]\n",
      " [  27    0   15  565    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 58 : main_model accuracy on all test data:  0.8946\n",
      "precision value: 0.9356486159533646\n",
      "recall value: 0.9170554947469786\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 838 2911    0    0    0]\n",
      " [  50    0 1038   70    0]\n",
      " [  34    0   19  554    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 59 : main_model accuracy on all test data:  0.9739\n",
      "precision value: 0.963376336564939\n",
      "recall value: 0.9672971982085304\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3925    1    0    1    0]\n",
      " [ 120 3629    0    0    0]\n",
      " [  17    0 1054   87    0]\n",
      " [   8    0   17  582    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 60 : main_model accuracy on all test data:  0.8844\n",
      "precision value: 0.9400232657663125\n",
      "recall value: 0.9017135088108917\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 913 2836    0    0    0]\n",
      " [  72    0 1062   24    0]\n",
      " [  51    0   49  507    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 61 : main_model accuracy on all test data:  0.9700\n",
      "precision value: 0.9631401132730282\n",
      "recall value: 0.9546422653124313\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 104 3645    0    0    0]\n",
      " [  57    0 1027   74    0]\n",
      " [  33    0   19  555    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 62 : main_model accuracy on all test data:  0.8903\n",
      "precision value: 0.9360999105356225\n",
      "recall value: 0.918844782115257\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 898 2851    0    0    0]\n",
      " [  49    0 1044   65    0]\n",
      " [  23    0   18  566    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 63 : main_model accuracy on all test data:  0.9729\n",
      "precision value: 0.9720148475707834\n",
      "recall value: 0.954767734832122\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 100 3649    0    0    0]\n",
      " [  45    0 1078   35    0]\n",
      " [  46    0   33  528    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 64 : main_model accuracy on all test data:  0.9276\n",
      "precision value: 0.9452861227868354\n",
      "recall value: 0.9400114983520769\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 548 3201    0    0    0]\n",
      " [  29    0 1047   82    0]\n",
      " [  19    0   16  572    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 65 : main_model accuracy on all test data:  0.8726\n",
      "precision value: 0.9280677875864963\n",
      "recall value: 0.911477084016526\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1077 2672    0    0    0]\n",
      " [  32    0 1049   77    0]\n",
      " [  20    0   17  570    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 66 : main_model accuracy on all test data:  0.9778\n",
      "precision value: 0.9604537454232874\n",
      "recall value: 0.9652707338375912\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [  53 3696    0    0    0]\n",
      " [  18    0 1027  113    0]\n",
      " [  16    0   12  579    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 67 : main_model accuracy on all test data:  0.9115\n",
      "precision value: 0.9473086306353073\n",
      "recall value: 0.9323679382727335\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 724 3025    0    0    0]\n",
      " [  34    0 1080   44    0]\n",
      " [  21    0   26  560    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 68 : main_model accuracy on all test data:  0.9547\n",
      "precision value: 0.963504602984043\n",
      "recall value: 0.9488667760052458\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 267 3482    0    0    0]\n",
      " [  70    0 1042   46    0]\n",
      " [  31    0   20  556    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 69 : main_model accuracy on all test data:  0.8974\n",
      "precision value: 0.9391700285660795\n",
      "recall value: 0.9207175704137898\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 835 2914    0    0    0]\n",
      " [  35    0 1064   59    0]\n",
      " [  36    0   20  551    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 70 : main_model accuracy on all test data:  0.9736\n",
      "precision value: 0.9704723696533921\n",
      "recall value: 0.9668122598445317\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 141 3608    0    0    0]\n",
      " [  20    0 1086   52    0]\n",
      " [  20    0   20  567    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 71 : main_model accuracy on all test data:  0.9159\n",
      "precision value: 0.9428103847445175\n",
      "recall value: 0.9355349563058617\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 674 3075    0    0    0]\n",
      " [  24    0 1060   74    0]\n",
      " [  18    0   17  572    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 72 : main_model accuracy on all test data:  0.8725\n",
      "precision value: 0.9350464230309907\n",
      "recall value: 0.9037291816618052\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [1049 2700    0    0    0]\n",
      " [  66    0 1047   45    0]\n",
      " [  44    0   20  543    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 73 : main_model accuracy on all test data:  0.9796\n",
      "precision value: 0.9689692992333281\n",
      "recall value: 0.9654293681945953\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [  56 3693    0    0    0]\n",
      " [  21    0 1067   70    0]\n",
      " [  31    0   17  559    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 74 : main_model accuracy on all test data:  0.9367\n",
      "precision value: 0.9542462514769493\n",
      "recall value: 0.948905303862062\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 494 3255    0    0    0]\n",
      " [  22    0 1078   58    0]\n",
      " [  15    0   18  574    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 75 : main_model accuracy on all test data:  0.9721\n",
      "precision value: 0.96372229905812\n",
      "recall value: 0.9667459636399183\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 141 3608    0    0    0]\n",
      " [  18    0 1057   83    0]\n",
      " [  10    0   15  582    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 76 : main_model accuracy on all test data:  0.9112\n",
      "precision value: 0.9409655642651178\n",
      "recall value: 0.9335975264053813\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 715 3034    0    0    0]\n",
      " [  31    0 1050   77    0]\n",
      " [  14    0   15  578    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 77 : main_model accuracy on all test data:  0.9767\n",
      "precision value: 0.9662089743511357\n",
      "recall value: 0.9669660726980199\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [  91 3658    0    0    0]\n",
      " [  19    0 1060   79    0]\n",
      " [  18    0   16  573    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 78 : main_model accuracy on all test data:  0.9094\n",
      "precision value: 0.9447327463266484\n",
      "recall value: 0.9338610900911833\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 751 2998    0    0    0]\n",
      " [  26    0 1076   56    0]\n",
      " [  17    0   19  571    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 79 : main_model accuracy on all test data:  0.9743\n",
      "precision value: 0.9618640587651841\n",
      "recall value: 0.9654041547245346\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 102 3647    0    0    0]\n",
      " [  19    0 1041   98    0]\n",
      " [  15    0   12  580    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 80 : main_model accuracy on all test data:  0.9187\n",
      "precision value: 0.9501854499482393\n",
      "recall value: 0.9390936018120994\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 670 3079    0    0    0]\n",
      " [  25    0 1087   46    0]\n",
      " [  18    0   21  568    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 81 : main_model accuracy on all test data:  0.9359\n",
      "precision value: 0.9578999838116686\n",
      "recall value: 0.9448583900499733\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 494 3255    0    0    0]\n",
      " [  32    0 1087   39    0]\n",
      " [  28    0   22  557    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 82 : main_model accuracy on all test data:  0.9380\n",
      "precision value: 0.9568215159845057\n",
      "recall value: 0.9433064558553177\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 456 3293    0    0    0]\n",
      " [  39    0 1072   47    0]\n",
      " [  34    0   19  554    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 83 : main_model accuracy on all test data:  0.9356\n",
      "precision value: 0.9495234120977788\n",
      "recall value: 0.9485358400652644\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 495 3254    0    0    0]\n",
      " [  20    0 1059   79    0]\n",
      " [   9    0   15  583    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 84 : main_model accuracy on all test data:  0.9805\n",
      "precision value: 0.9711640240825588\n",
      "recall value: 0.9669766494501367\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [  52 3697    0    0    0]\n",
      " [  26    0 1069   63    0]\n",
      " [  28    0   17  562    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 85 : main_model accuracy on all test data:  0.9324\n",
      "precision value: 0.9509231509967225\n",
      "recall value: 0.9489646014943339\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 542 3207    0    0    0]\n",
      " [  14    0 1076   68    0]\n",
      " [   9    0   15  583    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 86 : main_model accuracy on all test data:  0.9751\n",
      "precision value: 0.9663317547333893\n",
      "recall value: 0.9710241693654723\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 127 3622    0    0    0]\n",
      " [  13    0 1066   79    0]\n",
      " [   5    0   14  588    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 87 : main_model accuracy on all test data:  0.9460\n",
      "precision value: 0.9588574531867543\n",
      "recall value: 0.9551533093177076\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 411 3338    0    0    0]\n",
      " [  24    0 1079   55    0]\n",
      " [  11    0   17  579    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 88 : main_model accuracy on all test data:  0.9255\n",
      "precision value: 0.9459511176610513\n",
      "recall value: 0.9441147245899492\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 597 3152    0    0    0]\n",
      " [  16    0 1063   79    0]\n",
      " [   9    0   14  584    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 89 : main_model accuracy on all test data:  0.9470\n",
      "precision value: 0.9548890577427006\n",
      "recall value: 0.9529485355172345\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 382 3367    0    0    0]\n",
      " [  21    0 1063   74    0]\n",
      " [  16    0   15  576    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 90 : main_model accuracy on all test data:  0.9051\n",
      "precision value: 0.9388277540887083\n",
      "recall value: 0.9341360590068184\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 797 2952    0    0    0]\n",
      " [  12    0 1067   79    0]\n",
      " [   9    0   14  584    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 91 : main_model accuracy on all test data:  0.9039\n",
      "precision value: 0.9443791466751035\n",
      "recall value: 0.9295781333692403\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 801 2948    0    0    0]\n",
      " [  29    0 1080   49    0]\n",
      " [  23    0   20  564    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 92 : main_model accuracy on all test data:  0.9595\n",
      "precision value: 0.9630453950565275\n",
      "recall value: 0.9604245187500687\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 271 3478    0    0    0]\n",
      " [  26    0 1072   60    0]\n",
      " [  14    0   17  576    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 93 : main_model accuracy on all test data:  0.9297\n",
      "precision value: 0.9503951126341563\n",
      "recall value: 0.9486892547697877\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 576 3173    0    0    0]\n",
      " [  10    0 1083   65    0]\n",
      " [   6    0   17  584    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 94 : main_model accuracy on all test data:  0.9771\n",
      "precision value: 0.9732629733486059\n",
      "recall value: 0.9646336057090565\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [  88 3661    0    0    0]\n",
      " [  35    0 1078   45    0]\n",
      " [  29    0   22  556    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 95 : main_model accuracy on all test data:  0.9025\n",
      "precision value: 0.9434864787666968\n",
      "recall value: 0.9356742292084533\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 850 2899    0    0    0]\n",
      " [   8    0 1098   52    0]\n",
      " [   5    0   21  581    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 96 : main_model accuracy on all test data:  0.9830\n",
      "precision value: 0.9678475180125939\n",
      "recall value: 0.9744746409248414\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [  42 3707    0    0    0]\n",
      " [  13    0 1054   91    0]\n",
      " [   4    0   12  591    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 97 : main_model accuracy on all test data:  0.8971\n",
      "precision value: 0.9453693952164095\n",
      "recall value: 0.9239156539326269\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 866 2883    0    0    0]\n",
      " [  34    0 1094   30    0]\n",
      " [  24    0   33  550    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 98 : main_model accuracy on all test data:  0.9679\n",
      "precision value: 0.9689039286681466\n",
      "recall value: 0.9665735449498396\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 204 3545    0    0    0]\n",
      " [  22    0 1085   51    0]\n",
      " [  13    0   17  577    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 99 : main_model accuracy on all test data:  0.9169\n",
      "precision value: 0.9458513672061126\n",
      "recall value: 0.9426797884343386\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 701 3048    0    0    0]\n",
      " [  10    0 1083   65    0]\n",
      " [   4    0   17  586    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 100 : main_model accuracy on all test data:  0.9190\n",
      "precision value: 0.9440735712858684\n",
      "recall value: 0.9416801377041809\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 665 3084    0    0    0]\n",
      " [  14    0 1068   76    0]\n",
      " [   6    0   16  585    0]\n",
      " [   0    0    0    0  165]]\n",
      "Updating model :model0\n",
      "Updating model :model1\n",
      "Updating model :model2\n",
      "Updating model :model3\n",
      "Updating model :model4\n",
      "Iteration 101 : main_model accuracy on all test data:  0.9272\n",
      "precision value: 0.9522511221289168\n",
      "recall value: 0.948923231798051\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 614 3135    0    0    0]\n",
      " [   8    0 1098   52    0]\n",
      " [   4    0   20  583    0]\n",
      " [   0    0    0    0  165]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    model_dict=send_main_model_to_nodes_and_update_model_dict(main_model, model_dict, number_of_slices)\n",
    "    start_train_end_node_process_without_print(number_of_slices)\n",
    "    main_model= set_averaged_weights_as_main_model_weights_and_update_main_model(main_model,model_dict, number_of_slices) \n",
    "    test_loss, test_accuracy = validation(main_model, test_dl, main_criterion)\n",
    "    print(\"Iteration\", str(i+2), \": main_model accuracy on all test data: {:7.4f}\".format(test_accuracy)) \n",
    "    confusion_mat(main_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "234ecd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision value: 0.9522511221289168\n",
      "recall value: 0.948923231798051\n",
      "confusion matrix for normal scenario for slices : 5\n",
      "[[3926    0    0    1    0]\n",
      " [ 614 3135    0    0    0]\n",
      " [   8    0 1098   52    0]\n",
      " [   4    0   20  583    0]\n",
      " [   0    0    0    0  165]]\n"
     ]
    }
   ],
   "source": [
    "confusion_mat(main_model, test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2410d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
